---
title: "Accessing poverty and inequality data from the World Bank in R"
subtitle: "Part 2"
author: Giorgia Cecchinato, gcecchinato@worldbank.org
format:
  html:
    toc: true
    number-sections: true
---

**Set-up**

```{r}
#| echo: true
#| output: false
library(pipr)
library(tidyverse)
library(here)
# install.packages("joyn")
# library(joyn) # not necessary, but nice features, and developed by our own team!
```

# Introduction

The **objectives** of this session are to:

1.  Learn how PIP data are actually calculated by replicating them (Nigeria).

-   **Replication of survey years** using percentiles (and microdata, but data not available for you to use).
-   **Replication of reference years** (interpolation).
-   Calculate the **international poverty line**.

::: {.callout-note}
These exercises were originally written in Stata by Samuel Kofi Tetteh Bah (stettehbaah\@worldbank.org). A version of these exercises are available in the Stata .do file `Stata_part_2.do`.
:::

2.  Explore the data through one **visualization** exercise showing the difference between the societal and international poverty line (**SPL vs IPL**).

# Replicate PIP Data for Nigeria (Survey Years)

First we load the target values:

```{r}
nga_hc <- get_stats(country = "NGA") |>
  select(country_code, year, headcount) |>
  rename(hc_pip = headcount) # year = survey_year in this case

nga_hc |>
  DT::datatable(options = list(scrollX = TRUE))
```

## Version 1: Using percentiles

Microdata are not available for the public to download. They are only available for you to browse: [Microdata browsing](https://pip.worldbank.org/sol/sol-landing).

Instead, we provide access to **country-level percentile data (100)** for the survey years.

How to access percentile data for the survey years:

1.  Go to https://pip.worldbank.org/home

2.  Go to Further Indicators & Data

3.  Go to Percentiles ([Datacatalog Percentiles](https://datacatalog.worldbank.org/search/dataset/0063646))

4.  Download percentile data expressed in 2017 PPP dollars for the survey years.

```{r}
world_100bin <- read_csv(here("02_data","world_100bin.csv"))
world_100bin |>
  filter(country_code == "NGA", year == 2018) |>
  select(country_code, year, welfare_type, percentile, avg_welfare, 
         welfare_share, quantile, pop_share) |>
  filter(percentile %in% c(0, 1, 2, 3, 4, 5, 10, 40, 90, 100)) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

```{r}
nga_100bin <- world_100bin |>
  filter(country_code == "NGA") |>
  select(country_code, year, percentile, avg_welfare, pop_share) |>
  arrange(year, percentile) |> # just to make sure
  mutate(poor = avg_welfare < 2.15) |> # select individuals falling under default poverty line (y < z)
  group_by(country_code, year) |>
  summarize(hc_own = weighted.mean(poor, w = pop_share, na.rm = TRUE))

nga_100bin |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

```{r}
nga_100bin |>
  dplyr::left_join(nga_hc, by = c("country_code", "year"))|>
  mutate(d_hc = round(hc_pip/hc_own)) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

## Version 2: using actual microdata

First, we need to get auxiliary data for **CPI** and **PPPs**:

```{r}
# CPI
cpi_table <- get_aux("cpi") |>
  rename(cpi = value) |>
  select(country_code, year, cpi) |>
  filter(country_code == "NGA", year == 2018)

# PPP data
ppp_table <- get_aux("ppp") |>
  rename(ppp = value) |>
  select(country_code, year, ppp) |>
  filter(country_code == "NGA", year == 2017)
```

Then, we load the microdata (which you do not have access to!):

```{r}
library(haven)
nga2018 <- read_dta(here("02_data", "NGA2018.dta")) # you don't have access to this file!
nga2018 |>
  select(country_code, year, hhid, welfare, weight) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  head(n = 10) |>
  DT::datatable(options = list(scrollX = TRUE))
```

Merge with `cpi_table` and `ppp_table`:

```{r}
nga2018 <- nga2018 |>
  dplyr::left_join(cpi_table, by = c("country_code")) |>
  dplyr::left_join(ppp_table, by = c("country_code")) |>
  select(-year, year = year.x, country_code, welfare, cpi, ppp, weight)
```

```{r}
nga2018_hc_own <- nga2018 |>
  select(country_code, welfare, cpi, ppp, weight, year) |>
  mutate(welfare_ppp = welfare * (1/cpi) * (1/ppp) * (1/365)) |> # daily p.c. PPP terms
  mutate(poor = welfare_ppp < 2.15) |>
  group_by(country_code, year) |>
  summarize(hc_own = weighted.mean(poor, w = weight)) 

nga2018_hc_own
```

```{r}
nga_hc |>
  dplyr::filter(year == 2018)
```

# Replicate PIP Data for Nigeria (Reference Years)

In part 1 we looked at the difference between survey year estimates and reference year estimates, as well as the difference between `fill_gaps = TRUE` and `nowcast = TRUE`. Now, we are going to go through a replication of PIP data for reference years for Nigeria.

To do so, we need to:

1.  Get survey years estimates.

2.  Calculate welfare means for reference years.

3.  Calculate poverty headcount estimates based on welfare means for reference years.

## Get survey years estimates

Survey estimates are accessed as usual with `get_stats()`:

```{r}
nga_pip <- get_stats(country = "NGA", # note that we are not filling gaps
                     reporting_level = "national") |>
           select(country_code, welfare_time, mean)

head(nga_pip)
```

Note that this time we need `welfare_time` rather than year. `welfare_time` reports the correct timing of the survey and it is expressed in a decimal form, e.g. 2015.5 for a survey conducted in the middle of 2015.

## Get interpolated means

Welfare means are already calculated for us following the methodology described in the [PIP methodology handbook](https://datanalytics.worldbank.org/PIP-Methodology/lineupestimates.html#interpolations) and source code is available in the [repository](https://github.com/PIP-Technical-Team/wbpip/blob/PROD/R/predict_request_year_mean.R) of the `{wbpip}` package.

A brief overview:

### Extrapolations

$$
f\left(y_{\text {reference }}\right)=\frac{N A_{\text {reference }}}{N A_{\text {survey }}} \times f\left(y_{\text {survey }}\right)
$$ where $NA$ is GDP per capita. So estimated means are just scaled survey means based on the ratio of GDP p.c. We apply a *pass-through* methodology for: - **India**: only 0.7 of growth in GDP will be passed to welfare in urban areas and 0.55 in rural areas. - **Years between 2015-2018**: 0.7 of growth in GDP will be passed to welfare.

### Interpolations

Depends on whether:

$$
\operatorname{sign}\left(\frac{\mu_{\text {survey } 2}}{\mu_{\text {survey } 1}}-1\right)=\operatorname{sign}\left(\frac{N A_{\text {survey } 2}}{N A_{\text {reference }}}-1\right)=\operatorname{sign}\left(\frac{N A_{\text {reference }}}{N A_{\text {survey } 1}}-1\right)
$$ is true.

Easier in code terms:

```{r}
#| eval: false
is_same_direction <- function(x, y) {
  (x[2] - x[1]) * (y[2] - y[1]) > 0
}
# with x = c(mu_survey1, mu_survey2) and y = c(NA_survey1, NA_survey2)
```

If so, we apply same direction, otherwise, diverging direction interpolation:

-   **Same direction** : we extrapolate means like so:

$$
\mu_{\text {reference }}=\left(\mu_{\text {survey } 2}-\mu_{\text {survey } 1}\right) \times \frac{N A_{\text {reference }}-N A_{\text {survey } 1}}{N A_{\text {survey } 2}-N A_{\text {survey } 1}}+\mu_{\text {survey } 1}
$$

-   **Diverging direction** : means are extrapolated forward by the national account growth rate using the early survey and backwards using the later survey.

We can access them using the function `get_aux("interpolated_means")`:

```{r}
means_table <- get_aux("interpolated_means") |>
  select(country_code, year, welfare_time, welfare_type, survey_time, predicted_mean_ppp) |>
  filter(country_code == "NGA")
```

```{r}
means_table |>
  head(n=5) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

## Calculate interpolated values

Next, we need to calculate interpolated values for poverty estimates:

```{r}
# First we merge the interpolated means with survey estimates
merged_data <- means_table |>
  dplyr::left_join(nga_pip, by = c("country_code", "welfare_time"))
```

Then, we need to:

1.  Scale the adjusted poverty line, using the ratio between the survey `mean` and the `predicted_mean_ppp` (instead of adjusting the whole distribution).
2.  Calculate interpolation weights based on the distance between the `welfare_time` and the reference `year.`
3.  Normalize the interpolation weights (calculate `interpolation_shr.`)

```{r}
merged_data_step1 <- merged_data |> 
  mutate(pl_to_query = 2.15 * mean / predicted_mean_ppp) |> # scaled poverty line
  filter(!is.na(pl_to_query)) 
```

```{r}
#| code-fold: true
merged_data_step1 |>
  select(year, welfare_time, mean, predicted_mean_ppp, pl_to_query) |>
  head(n = 10) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

```{r}
merged_data_step2 <- merged_data_step1 |> 
  group_by(year) |>  
  mutate(
    interpol_wt = 1 / abs(welfare_time - year), # Raw weights based on distance
    interpol_wtt = sum(interpol_wt, na.rm = TRUE), # Total weights within group
    interpol_shr = interpol_wt / interpol_wtt, # Normalized weights
    survey_year = floor(welfare_time) # Survey year as integer
  ) |> 
  ungroup() |> # Ungroup for further processing
  arrange(country_code, year, welfare_time)
```

```{r}
merged_data_step2 |>
  select(year, welfare_time, survey_year, mean, predicted_mean_ppp, pl_to_query, interpol_wt, interpol_wtt, interpol_shr) |>
  head(n= 10) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

Finally we are ready for the poverty headcount estimation, which we'll do in two steps:

First, we use `get_stats()` to calculate the new poverty headcount at each scaled poverty line (`pl_to_query`), and at each `survey_year.` For this exercise you can loop through the values, use `rowwise()` operations, or use `{purrr}` like we did here:

```{r}

merged_data_step3 <- merged_data_step2 |>
  filter(year %in% 2015:2020) # restricted to some years to reduce computational time

pl_queries <- merged_data_step3 |> 
  mutate( # note I am running this within a mutate function so for each hc estimate I run the get_stats function for a given year and a given (adjusted) poverty line
    hc = purrr::map2_dbl(
      .x = survey_year,
      .y = pl_to_query,
      ~ get_stats(
        country = "NGA",
        reporting_level = "national",
        year = .x,
        povline = .y
      )$headcount[1]
    )
  )
```

```{r}
pl_queries |> 
  select(year, welfare_time, survey_year, pl_to_query, hc) |>
  mutate(across(where(is.numeric), ~ round(., digits = 3))) |>
  DT::datatable(options = list(scrollX = TRUE))
```

Then, we calculate the weighted average of those headcounts estimates `hc` based on the share of the time (`interpolated_shr`)

```{r}
nga_final_estimates <- pl_queries |>
  group_by(year) |>
  summarize(hc = weighted.mean(hc, interpol_shr, na.rm = TRUE)) |>
  ungroup()

str(nga_final_estimates)
```

And we check the results:

```{r}
nga_pip_fillgaps <- get_stats(country = "NGA", # note that we are not filling gaps
                     reporting_level = "national") |>
                    select(country_code, year, hc_target = headcount) # year is = reference year!
  
nga_final_estimates |>
  dplyr::left_join(nga_pip_fillgaps, by=c('year'))|>
  mutate(d_hc = hc_target/hc)|>
  summary()
```

# Estimate Global and Regional Poverty

In Part 1, we looked at the function `get_wb()`, which gives you access to regional and global estimates of poverty and inequality metrics.

In this session, we will look at how exactly those numbers are calculated using country-level data and auxiliary tables (accessed with `get_aux()`).

First, note that there is not a one-to-one correspondence between the regions in the regional estimates and the regions in the country-level data:

```{r}
pip_regional <- get_wb()

pip_regional |>
  distinct(region_code, region_name)
```

```{r}
country_estimates <- get_stats(fill_gaps = TRUE)

country_estimates |>
  distinct(region_code, region_name)
```

We will need to calculate regional estimates for Eastern and Southern Africa (AFE) and Western and Central Africa (AFW) separately.

## Get Population Data and Country Reference Table

You can use the function `get_aux()` to access population data for each country in PIP. We only need national level estimates, so we filter the data accordingly (and we keep Argentina, which is calculated based on urban population).

```{r}
pop_tables <- 
  get_aux("pop") |>
  filter(data_level == "national" | country_code == "ARG") |>
  rename(pop = value, reporting_level = data_level) |>
  filter(year %in% c(1990:2022)) |>
  mutate(year = as.numeric(as.character(year)))

pop_tables
```

Data are now identified uniquely by `country_code`, `year`, and `reporting_level`.

We get additional country-level reference table to match country codes with regions.

```{r}
country_tables <- get_aux("country_list") |>
  select(region_code, region, country_code, country_name, 
         africa_split, africa_split_code) |>
  rename(region_name = region)

country_tables |> 
  filter(region_code == "SSA")
```

## Obtain reference-year poverty estimates and Merge

We then get country-level estimates at the national level for the poverty headcount ratio:

```{r}
country_estimates <- country_estimates |>
  select(country_code, year, reporting_level, headcount) |>
  filter(reporting_level == "national" | country_code == "ARG") |>
  filter(year %in% c(1990:2022)) |>
  rename(hc = headcount)
```

And check that they are uniquely identified:

```{r}
library(joyn) # This is a package developed by my team!

joyn::is_id(country_estimates, c('country_code', 'year'))
```

We then merge them to population and country reference tables:

```{r}
country_estimates <- country_estimates |>
  dplyr::left_join(pop_tables, by = c("country_code", "year", "reporting_level")) |>
  dplyr::left_join(country_tables, by = "country_code") |>
  arrange(country_code, year, reporting_level)
```

## Get Africa Split Codes for AFW and AFE and Append

We want to calculate regional estimates for Eastern and Southern Africa (AFE) and Western and Central Africa (AFW) separately. To do so, we can use the `africa_split_code` variable:

```{r}
subreg <- country_estimates |>
  filter(africa_split_code %in% c("AFW", "AFE")) |>
  mutate(region_code = africa_split_code, # Here we substitute the region_code with the respective africa_split_code.
         subregion = 1, 
         region_name = africa_split_code)

subreg |> head(n=5)
```

```{r}
country_estimates_complete <- country_estimates |>
  bind_rows(subreg)

# Note correspondeces now:
country_estimates_complete |> 
  select(region_code, africa_split, africa_split_code) |>
  distinct()
```

## Calculate Global Poverty Estimates

```{r}
global_poverty <- country_estimates_complete %>%
  filter(subregion != 1) %>% # Removes duplicates of African countries used for subr-egional estimates
  group_by(year) %>%
  summarize(hc = weighted.mean(hc, pop, na.rm = TRUE), 
            pop = sum(pop, na.rm = TRUE),
            region_code = "WLD",
            region_name = "World")
```

```{r}
regional_poverty <- country_estimates_complete %>%
  group_by(region_code, region_name, year) %>%
  summarize(hc = weighted.mean(hc, pop, na.rm = TRUE), 
            pop = sum(pop, na.rm = TRUE))
```

```{r}
regional_estimates <- bind_rows(regional_poverty, global_poverty) |> rename(hc_own = hc)
```

## Compare with already calculated regional aggregates

```{r}
regional_comparison <- pip_regional |>
  select(region_code, year, hc = headcount) |>
  filter(year >= 1990) |>
  dplyr::full_join(regional_estimates, by = c("region_code", "year"))|>
  mutate(d_hc = hc/hc_own)
```

```{r}
mean_d_hc <- mean(regional_comparison$d_hc, na.rm = TRUE)
if (round(mean_d_hc) != 1) {
  warning("The mean of d_hc is not approximately 1. Check the merge.")
} # We're okay!
```

# Calculate the international poverty line

The IPL is now derived as the median of the national poverty lines of 28 of the worldâ€™s poorest countries, expressed in 2017 PPPs. For convenience, we will make use of an already generated dataset containing headcount ratios for this set of countries. More on the international poverty line (theory and Q&A): [Factseet on Adjustment to the Poverty Line](https://www.worldbank.org/en/news/factsheet/2022/05/02/fact-sheet-an-adjustment-to-global-poverty-lines#9). Note that you can retrieve the poverty lines also with:

```{r}
#| eval: false
get_aux("national_poverty_lines")
```

But you need to filter them accordingly.

## Load Data and query PIP

First we load the headcount ratios for the 28 countries:

```{r}
npl_data <- read_stata(here("02_data", "national_poverty_rates_lic.dta"))
```

Next we query PIP to derive the poverty line at a given headcount. To do so, we need to use the argument `popshare`, and loop through (or use `{purrr}` for vectorized loops) each country and headcount ratio:

```{r}
harmonized_npl <- npl_data |> 
  mutate(
    pip_data = map2(
      .x = country_code, 
      .y = headcount_nat, 
      .f = ~ get_stats(
      country = .x, 
      year = "all", 
      popshare = .y
    ))
  )
```

```{r}
harmonized_npl_unnested <- harmonized_npl |>
  select(country_code, year, pip_data) |>
  # Unnest the fetched data
  unnest(pip_data, names_sep = ".")

harmonized_npl_unnested |> head(n=5)
```

```{r}
harmonized_npl_unnested <-
harmonized_npl_unnested |>
  # Filter and prepare final dataset
  filter(pip_data.year == year, 
         pip_data.welfare_type == "consumption") |>
  select(
    country_code, pip_data.region_code, pip_data.year, pip_data.welfare_time, pip_data.headcount, 
    pip_data.poverty_line, pip_data.reporting_level, pip_data.welfare_type
  ) |> 
  rename(harm_npl = pip_data.poverty_line) |> 
  mutate(harm_npl = as.numeric(harm_npl))

harmonized_npl_unnested
```

## Calculate the International Poverty Line (IPL)

```{r}
ipl <- harmonized_npl_unnested |> 
  summarize(ipl = median(harm_npl, na.rm = TRUE)) |> 
  pull(ipl)
```

## Visualize Harmonized Poverty Lines by Region

```{r}
#| fig-height: 6
ggplot(harmonized_npl_unnested, 
       aes(x = reorder(pip_data.region_code, harm_npl), y = harm_npl, fill = pip_data.region_code)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.6) +
  geom_jitter(color = "darkblue", size = 1, width = 0.2, alpha = 0.7) +
  geom_hline(aes(yintercept = ipl), colour = "red") +
  labs(
    title = "Harmonized National Poverty Lines by Region",
    subtitle = paste("Median IPL:", round(ipl, 2), "2017 PPP dollars"),
    x = "Region",
    y = "Harmonized National Poverty Line (PPP $)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )
```


# Visualization Exercise: SPL vs IPL.

Plot the different trends in poverty headcount ratios when calculated based on the IPL vs the SPL for Italy (or another country of your choice) using all available years. Hint: `get_stats()` will give you the data you need (the variable `spl` reports the societal poverty line at default 2017 PPPs). Another hint: you need to use a loop or vectorization!

```{r}
#| code-fold: true
country_chosen <- "ITA"

country_spl <- get_stats(country = country_chosen)  |> 
  #filter(year>2005) |>
  select(year, spl)


country_spl_data <- map2_dfr(.x = country_spl$spl, 
        .y = country_spl$year,
        .f = ~ get_stats(country = country_chosen, 
                         povline = .x,
                         year = .y)) |>
  select(country_code, year, poverty_line, headcount)

country_pl_data <- get_stats(country = country_chosen) |>
  select(year, poverty_line, headcount)
  #filter(year>2005)
```

```{r}
ggplot() +
  geom_point(data = country_spl_data, aes(x = year, y = headcount), color = "blue") +
  geom_line(data = country_spl_data, aes(x = year, y = headcount), color = "blue") +
  geom_point(data = country_pl_data, aes(x = year, y = headcount), color = "red") +
  geom_line(data = country_pl_data, aes(x = year, y = headcount), color = "red") +
  labs(title = paste("Headcount ratio SPL vs PL in", country_chosen),
       x = "Year",
       y = "Headcount ratio") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
